import os
import json
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
import nibabel as nib
from PIL import Image
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, Dataset
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import f_regression
from sklearn.decomposition import PCA
from model import RNAEncoder, ResNetMultiChannel, CLIPModel, ContrastiveLoss,LightRNATransformer,ViTMultiChannel,ImprovedRNAEncoder

rna_path = r'C:\Users\95602\Desktop\ultrasound-contrastivemodels-klr-us-rna\TCIA\TCIA\combined_summary_filtered.csv'
image_directory = r'C:\Users\95602\Desktop\ultrasound-contrastivemodels-klr-us-rna\TCIA\TCIA'
bbox_json_path = r'C:\Users\95602\PycharmProjects\PythonProject2\bbox_coords.json'
SAVE_DIR = r'C:\Users\95602\Desktop\ultrasound-contrastivemodels-klr-us-rna\TCIA\TCIA'
N_CHANNELS = 16
IMG_SIZE = 224
EPOCHS = 100
BATCH_SIZE = 4
EMBEDDING_DIM = 256

os.makedirs(SAVE_DIR, exist_ok=True)

rna_df = pd.read_csv(rna_path, index_col=0)
rna_df = rna_df.fillna(0).T
rna_df.index = rna_df.index.str.strip()

y = rna_df['CD274'].values
X = rna_df.values
genes = np.array(rna_df.columns)
cd274_idx = np.where(genes == 'CD274')[0][0]
X_for_select = np.delete(X, cd274_idx, axis=1)
genes_for_select = np.delete(genes, cd274_idx)

F_stat, pvals = f_regression(X_for_select, y)
selected = pvals < 0.01

X_selected = X_for_select[:, selected]
genes_selected = genes_for_select[selected]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_selected)

pca = PCA(n_components=0.95, random_state=42)
X_pca = pca.fit_transform(X_scaled)

rna_df_filtered = pd.DataFrame(X_pca, index=rna_df.index)

with open(bbox_json_path, 'r') as f:
    bbox_coords = json.load(f)
nifti_files = []
for root, _, files in os.walk(image_directory):
    for fname in files:
        if fname.lower().endswith('.nii') or fname.lower().endswith('.nii.gz'):
            nifti_files.append(os.path.join(root, fname))

rna_samples, image_paths = [], []
for sample_id in rna_df_filtered.index:
    matches = [p for p in nifti_files if os.path.basename(p) in (f"{sample_id}.nii.gz", f"{sample_id}.nii")]
    if not matches:
        continue
    img_path = matches[0]
    seg_key = 'seg' + sample_id.replace('-', '') + '.nii.gz'
    if seg_key not in bbox_coords:
        continue
    rna_samples.append(rna_df_filtered.loc[sample_id])
    image_paths.append(img_path)

rna_df_filtered = pd.DataFrame(rna_samples)

rna_train, rna_val, img_train_paths, img_val_paths = train_test_split(
    rna_df_filtered, image_paths, test_size=0.2, random_state=42
)

def strip_nii_suffix(filename):
    return filename.replace('.nii.gz', '').replace('.nii', '')

def sample_slices(total_slices, n=N_CHANNELS):
    if total_slices < n:
        idxs = list(range(total_slices)) + [total_slices // 2] * (n - total_slices)
        return idxs[:n]
    else:
        return np.linspace(0, total_slices - 1, n, dtype=int)

class SimpleRNACustomDataset(Dataset):
    def __init__(self, rna_data, img_paths, bbox_path, img_size=IMG_SIZE, n_channels=N_CHANNELS):
        self.rna = rna_data.reset_index(drop=True)
        self.img_paths = img_paths
        with open(bbox_path, 'r') as f:
            self.bbox = json.load(f)
        self.img_size = img_size
        self.n_channels = n_channels

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        rna_vec = torch.tensor(self.rna.iloc[idx].values, dtype=torch.float)
        path = self.img_paths[idx]
        vol = nib.load(path).get_fdata()
        fname = os.path.basename(path)
        sample_id_core = strip_nii_suffix(fname)
        seg_key = 'seg' + sample_id_core.replace('-', '') + '.nii.gz'

        bbox = self.bbox[seg_key]
        x0, x1 = sorted((bbox['x_min'], bbox['x_max']))
        y0, y1 = sorted((bbox['y_min'], bbox['y_max']))
        z0, z1 = sorted((bbox['z_min'], bbox['z_max']))
        roi = vol[x0:x1, y0:y1, z0:z1]

        roi = (roi - roi.min()) / (roi.max() - roi.min() + 1e-8)

        slice_idxs = sample_slices(roi.shape[2], n=self.n_channels)
        imgs = [roi[:, :, i] for i in slice_idxs]
        imgs = np.stack(imgs, axis=0)

        imgs_resized = []
        for i in range(self.n_channels):
            img = Image.fromarray((imgs[i] * 255).astype(np.uint8))
            img = img.resize((self.img_size, self.img_size))
            imgs_resized.append(np.array(img, dtype=np.float32) / 255.0)

        imgs_resized = np.stack(imgs_resized, axis=0)
        imgs_tensor = torch.tensor(imgs_resized, dtype=torch.float)

        return rna_vec, imgs_tensor

train_ds = SimpleRNACustomDataset(rna_train, img_train_paths, bbox_json_path)
val_ds = SimpleRNACustomDataset(rna_val, img_val_paths, bbox_json_path)

train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

input_dim = rna_df_filtered.shape[1]

model = CLIPModel(
    ImprovedRNAEncoder(input_dim=input_dim, embedding_dim=EMBEDDING_DIM),
    ResNetMultiChannel(n_channels=N_CHANNELS, embedding_dim=EMBEDDING_DIM)
).to(device)

criterion = ContrastiveLoss(temperature=0.5)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='min',
    factor=0.5,
    patience=10,
    verbose=True,
    min_lr=1e-7,
    threshold=1e-4
)

class ImprovedEarlyStopping:
    def __init__(self, patience=25, min_delta=1e-3):
        self.patience = patience
        self.min_delta = min_delta
        self.best_loss = np.inf
        self.counter = 0
        self.best_weights = None

    def __call__(self, loss, model):
        if loss < self.best_loss - self.min_delta:
            self.best_loss = loss
            self.counter = 0
            self.best_weights = model.state_dict().copy()
        else:
            self.counter += 1

        if self.counter >= self.patience:
            if self.best_weights:
                model.load_state_dict(self.best_weights)
            return True
        return False

early_stop = ImprovedEarlyStopping()

def compute_similarity_metrics(model, data_loader, device):
    model.eval()
    all_rna_emb, all_img_emb = [], []

    with torch.no_grad():
        for rna_vec, imgs in data_loader:
            rna_vec, imgs = rna_vec.to(device), imgs.to(device)
            rna_emb, img_emb = model(rna_vec, imgs)
            all_rna_emb.append(rna_emb.cpu())
            all_img_emb.append(img_emb.cpu())

    all_rna_emb = torch.cat(all_rna_emb, dim=0)
    all_img_emb = torch.cat(all_img_emb, dim=0)

    similarity_matrix = torch.matmul(
        F.normalize(all_rna_emb, p=2, dim=-1),
        F.normalize(all_img_emb, p=2, dim=-1).T
    )

    _, predicted = similarity_matrix.max(1)
    labels = torch.arange(len(all_rna_emb))
    accuracy = (predicted == labels).float().mean().item()
    diagonal_sim = similarity_matrix.diag().mean().item()

    return accuracy, diagonal_sim

best_val_loss = float('inf')
best_model_state = None

for epoch in range(1, EPOCHS + 1):
    model.train()
    train_loss, train_batches = 0.0, 0

    for batch_idx, (rna_vec, imgs) in enumerate(train_loader):
        rna_vec, imgs = rna_vec.to(device), imgs.to(device)

        emb_r, emb_i = model(rna_vec, imgs)
        loss = criterion(emb_r, emb_i)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        train_batches += 1

    train_loss /= max(train_batches, 1)

    model.eval()
    val_loss, val_batches = 0.0, 0

    with torch.no_grad():
        for rna_vec, imgs in val_loader:
            rna_vec, imgs = rna_vec.to(device), imgs.to(device)
            emb_r, emb_i = model(rna_vec, imgs)
            loss = criterion(emb_r, emb_i)
            val_loss += loss.item()
            val_batches += 1

    val_loss /= max(val_batches, 1)

    scheduler.step(val_loss)

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        best_model_state = model.state_dict().copy()

    if early_stop(val_loss, model):
        break

final_model_path = os.path.join(SAVE_DIR, "7615best_clip_lrp01_pca80_512d_no_augment.pth")
torch.save(best_model_state, final_model_path)
print(f"Model saved to: {final_model_path}")

model.load_state_dict(best_model_state)
final_train_acc, final_train_sim = compute_similarity_metrics(model, train_loader, device)
final_val_acc, final_val_sim = compute_similarity_metrics(model, val_loader, device)
